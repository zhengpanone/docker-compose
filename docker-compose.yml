services:

  portainer:
    image: portainer/portainer:latest
    container_name: portainer
    ports:
    - "9000:9000"
    volumes:
    - /opt/dockerstore/portainer/data:/data
    - /var/run/docker.sock:/var/run/docker.sock


  mysql:
    hostname: mysql
    container_name: 'mysql'
    image: mysql:5.7
    privileged: true
    restart: always
    ports:
      - "3306:3306"
    environment: 
      MYSQL_ROOT_PASSWORD: 'root'
      # MYSQL_ALLOW_EMPTY_PASSWORD: 'no'
      TZ: Asia/Shanghai
    volumes:
      - /opt/dockerstore/mysql/data:/var/lib/mysql
      - /opt/dockerstore/mysql/logs:/var/log/mysql
      - /opt/dockerstore/mysql/conf/my.cnf:/etc/mysql/conf.d/my.cnf
      # - ./init:/docker-entrypoint-initdb.d/   # sql初始化目录
    command:
      --max_connections=1000
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_general_ci
      --default-authentication-plugin=mysql_native_password
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
    networks:
      - my-network

  postgres:
    image: postgres:latest
    container_name: postgres
    hostname: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - 15432:5432
    volumes:
      - /opt/dockerstore/postgres/data:/var/lib/postgresql/data
      - /etc/localtime:/etc/localtime:ro #将外边时间直接挂载到容器内部，权限只读
    restart: always
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
    networks:
      - my-network


  # oracle_11g:
  #   image: registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g:latest
  #   container_name: oracle_11g
  #   ports:
  #     - 1521:1521
    # volumes:
    #   - /opt/dockerstore/oracle_11g/data:/home/oracle/app/oracle/oradata
    # restart: always

  redis:
    container_name: redis
    image: redis
    hostname: redis
    privileged: true
    ports:
      - "6379:6379"
    volumes:
      - /opt/dockerstore/redis/redis.conf:/etc/redis/redis.conf
      - /opt/dockerstore/redis/data:/data
    command: redis-server /etc/redis/redis.conf
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
    networks:
      - my-network

  mongodb:
    container_name: mongodb
    hostname: mogodb
    image: mongo:5.0.10-focal
    ports:
      - "27017:27017"
    restart: always
    command:
      - "--auth"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: root
      wiredTigerCacheSizeGB: 2
    volumes:
      - "/opt/dockerstore/mongo/data:/data/db"
      - "/opt/dockerstore/mongo/logs:/var/log/mongodb"
      - "/opt/dockerstore/mongo/config:/etc/mongo"
      - "/usr/share/zoneinfo/Asia/Shanghai:/etc/localtime"

  mongo-express:
    image: mongo-express
    container_name: mongo-express
    restart: always
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_SERVER: mongodb
      ME_CONFIG_MONGODB_ENABLE_ADMIN: false
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: root
      ME_CONFIG_BASICAUTH_USERNAME: root
      ME_CONFIG_BASICAUTH_PASSWORD: root
      # ME_CONFIG_MONGODB_URL: mongodb://root:root@mongo:27017/
    depends_on:
      - mongodb
  nginx:
    container_name: nginx
    image: nginx
    ports:
      - "9998:80"
    environment:
      TZ: Asia/Shanghai
    volumes:
      - /opt/dockerstore/nginx/html:/etc/nginx/html
      - /opt/dockerstore/nginx/conf.d:/etc/nginx/conf.d
      - /opt/dockerstore/nginx/log:/var/log/nginx

  # spug:
  #   image: openspug/spug-service
  #   container_name: spug
  #   privileged: true
  #   restart: always
  #   volumes:
  #     - /data/spug/service:/data/spug
  #     - /data/spug/repos:/data/repos
  #   ports:
  #     # 如果80端口被占用可替换为其他端口，例如: - "8000:80"
  #     - "8000:80"
  #   environment:
  #     - MYSQL_DATABASE=spug
  #     - MYSQL_USER=spug
  #     - MYSQL_PASSWORD=spug.cc
  #     - MYSQL_HOST=db
  #     - MYSQL_PORT=3306
  #   depends_on:
  #     - mysql

  nexus:
    image: sonatype/nexus3
    container_name: nexus3
    restart: always
    privileged: true
    environment:
      - TZ=Asia/Shanghai
    ports:
      - 8082:8081
    volumes:
      - /opt/dockerstore/nexus/nexus-data:/nexus-data

  gitlab:
    container_name: 'gitlab'
    hostname: 'gitlab'
    image: gitlab/gitlab-ce:latest
    privileged: true
    restart: always
    ports:
      - '9980:80'
      - '2224:22'
      - '2443:443'
    environment: 
      GITLAB_OMNIBUS_CONFIG: |
        external_url 'http://127.0.0.1:9980'
        gitlab_rails['gitlab_shell_ssh_port'] = 2224
      TZ: Asia/Shanghai
    volumes:
      - /opt/dockerstore/gitlab/config:/etc/gitlab:z
      - /opt/dockerstore/gitlab/logs:/var/log/gitlab:z 
      - /opt/dockerstore/gitlab/data:/var/opt/gitlab:z

  # neo4j:
  #   image: neo4j:latest
  #   container_name: neo4j
  #   restart: always
  #   environment:
  #     - NEO4J_AUTH=neo4j/neo4j # 默认用户名密码
  #     - NEO4J_dbms_memory_heap_maxSize=4G
  #   ports:
  #     - "7474:7474"
  #     - "7687:7687"
  #   volumes:
  #     - /opt/dockerstore/neo4j/data:/data
  #     - /opt/dockerstore/neo4j/config:/var/lib/neo4j/conf
  #     - /opt/dockerstore/neo4j/import:/var/lib/neo4j/import
  #     - /opt/dockerstore/neo4j/plugins:/plugins
  #     - /opt/dockerstore/neo4j/logs:/var/lib/neo4j/logs

  jenkins:
    image: jenkins/jenkins:2.462.2-lts-jdk17
    container_name: jenkins
    restart: always
    privileged: true
    environment:
      - TZ=Asia/Shanghai
      - JAVA_OPTS=-Xmx4096m -Xms2048m  # 调整JVM内存设置
    ports:
      - 8085:8080
      - 50000:50000
    volumes:
      - /opt/dockerstore/jenkins/jenkins-data:/var/jenkins_home
      - /opt/dockerstore/jenkins/jenkins-docker-certs:/certs/client:ro
      - /opt/dockerstore/jenkins/jenkins-logs:/var/log/jenkins  # 日志文件持久化
      - /var/run/docker.sock:/var/run/docker.sock  # 允许Jenkins构建Docker镜像
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

  nacos:
    hostname: nacos
    image: nacos/nacos-server:v2.1.2
    container_name: nacos
    privileged: true
    # restart: always
    environment:
      TZ: Asia/Shanghai
      MODE: standalone
      PREFER_HOST_MODE: hostname #如果支持主机名可以使用hostname,否则使用ip，默认也是ip
      SPRING_DATASOURCE_PLATFORM: mysql #数据源平台 仅支持mysql或不保存empty
      MYSQL_SERVICE_HOST: mysql
      MYSQL_SERVICE_DB_NAME: nacos
      MYSQL_SERVICE_PORT: 3306
      MYSQL_SERVICE_USER: root
      MYSQL_SERVICE_PASSWORD: root
      MYSQL_DATABASE_NUM: 1
      NACOS_APPLICATION_PORT: 8848
      MYSQL_SERVICE_DB_PARAM: characterEncoding=utf8&connectTimeout=10000&socketTimeout=3000&autoReconnect=true&useSSL=false&serverTimezone=UTC
      NACOS_AUTH_TOKEN: 15baf51c4de4f206e9dece30afe5208a4095d5f7f6b17b80d1b0990ea934ba7e56a6dbfc3e93b1b89ae0359f55ca22c41ed4508f1444864ee803d46d412fe63b
    volumes:
      - /opt/dockerstore/nacos/logs:/home/nacos/logs
      - /opt/dockerstore/nacos/plugins:/home/nacos/plugins
      - /opt/dockerstore/nacos/conf:/home/nacos/conf
    ports:
      - "8848:8848"
      - "9848:9848"
    networks:
      - my-network

  consul:
    hostname: consul
    image: consul:1.15.4
    container_name: consul
    ports:
      - "8300:8300" # 这是 Consul 服务器节点之间通信的端口。主要用于服务器节点间的 RPC (远程过程调用) 通信，例如进行领导选举、状态复制等。
      - "8301:8301" # 这个端口被用于 Consul 节点之间的 Serf LAN (局域网) 通信。Serf 是一个用于集群成员管理、故障检测和编排的工具，Consul 利用它进行健康检查和跟踪集群中的成员。8301 端口使用 TCP 和 UDP 协议。
      - "8302:8302" # 这个端口被用于 Consul 节点间的 Serf WAN (广域网) 通信。如果您有多个数据中心，它们将通过此端口相互通信确定其他数据中心的 Consul 节点的健康状况。同样，8302 端口同时支持 TCP 和 UDP 协议。
      - "8500:8500" # Consul HTTP 界面所用的端口
      - "8600:8600/udp" # Consul DNS 服务器所用的端口
    command: agent -dev -ui -client 0.0.0.0 # -dev 表示启动一个开发模式的 Consul 服务，-ui 开启用户界面，-client 0.0.0.0 允许来自宿主机的所有IP连接至Consul服务
    volumes:
      - /opt/dockerstore/consul/data:/consul/data # 将宿主机当前目录下的 consul_data 目录挂载到容器的 /consul/data
    restart: always
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
    networks:
      - my-network

  jaeger:
    container_name: jaeger
    image: jaegertracing/all-in-one:latest
    privileged: true
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"
    environment:
      COLLECTOR_ZIPKIN_HTTP_PORT: 9411
    networks:
      - my-network

  sentinel:
    image: bladex/sentinel-dashboard:1.8.4
    container_name: sentinel-dashboard
    ports:
      - "8858:8858"
    environment:
      JAVA_OPTS: "-Dserver.port=8858 -Dcsp.sentinel.dashboard.server=localhost:8858 -Dproject.name=sentinel-dashboard"

  # Kong Migrations，用于初始化数据库
  kong-migrations:
    image: kong:3.5
    container_name: kong-migrations
    depends_on:
      postgres: 
        condition: service_healthy
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: postgres
      KONG_PG_USER: postgres
      KONG_PG_PASSWORD: postgres
    command: ["kong", "migrations", "bootstrap"]
    restart: on-failure
    networks:
      - my-network

  # Kong API 网关
  kong:
    image: kong:3.5
    container_name: kong
    depends_on:
      kong-migrations:
        condition: service_started
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: postgres
      KONG_PG_USER: postgres
      KONG_PG_PASSWORD: postgres
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
      KONG_DNS_RESOLVER: "8.8.8.8,8.8.4.4" # 可选的 DNS 解析器
      KONG_CONSUL_HOST: consul
      KONG_LOG_LEVEL: info
    command: >
      kong start -c /etc/kong/kong.conf
    volumes:
      - /opt/dockerstore/kong/config/kong.conf:/etc/kong/kong.conf  # 挂载本地的kong.conf配置文件
      - /opt/dockerstore/kong/custom_plugins:/usr/local/kong/custom_plugins  # 挂载本地自定义插件目录
    ports:
      - "8000:8000"  # Proxy端口
      - "8002:8002"  # gui
      - "8443:8443"  # Proxy HTTPS端口
      - "8001:8001"  # 管理API端口
      - "8444:8444"  # 管理API HTTPS端口
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/status"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - my-network
  konga:
    image: pantsel/konga:latest
    container_name: konga
    environment:
      NODE_ENV: production
      # DB_ADAPTER: postgres
      # DB_HOST: 172.18.0.2
      # DB_PORT: 5432
      # DB_USER: postgres
      # DB_PASSWORD: postgres
      # DB_DATABASE: konga
    ports:
      - "1337:1337/tcp"
    depends_on:
      - kong
    volumes:
      - /opt/dockerstore/konga/kongadata:/app/kongadata  
    networks:
      - my-network

networks:
  my-network:
    driver: bridge
